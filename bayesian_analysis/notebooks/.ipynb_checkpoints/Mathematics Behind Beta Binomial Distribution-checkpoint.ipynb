{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematics Behind Beta Binomial Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **beta-binomial** distribution is a discrete probability distribution arising when the probability of success in each of a fixed or known number of Bernoulli trials is either unknown or random. Another way of saying this is that it is similar to the **binomial** distribution, except that in the binomial distribution, the probability of success is fixed, whereas in the beta-binomial distribution, the probability of success is random; in particular the probability of success follows the **beta distribution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will go over some of the mathematics explaining how to update the beta prior to obtain the posterior. In particular, we will explain what it means to say that the beta distribution is the **conjugate prior** to the binomial distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a binomial random variable $X$, which will consist of number of successes in $n$ Bernoulli trials. Recall that the probability mass function of a binomial random variable is:\n",
    "\n",
    "$$p(x) = {n \\choose x}q^x (1-q)^{n-x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $n$: Total number of trials\n",
    "2. $x$: Number of successes\n",
    "3. $q$: Some probability of success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to want to estimate the distribution of $q$ and we will do so using a beta distribution. Using a beta distribution has nice mathematical properties, which will at least be partially explained below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the probability density function of a beta distribution is given by\n",
    "$$p(q) = \\frac{q^{\\alpha - 1} (1-q)^{\\beta - 1}}{B(\\alpha, \\beta)}$$\n",
    "\n",
    "1. $\\alpha, \\beta$: hyperparameters of the beta distribution\n",
    "2. $B(\\alpha, \\beta)$ is the beta function (you can look this up here: https://en.wikipedia.org/wiki/Beta_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In bayesian probability theory, if the posterior distributions are in the same family as the prior probability distribution, the prior and posterior are then called **conjugate distributions** and the prior is called the **conjugate prior** for the likelihood function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, we are interested in estimating the probability distribution function of $q$ given some data (successes and failures). In other words, we are interested in estimating the posterior. Recall from Bayes Rule that the posterior is given by:\n",
    "\n",
    "$$P(q = x | s, f) = \\frac{P(s, f | x) P(x)}{\\int P(s, f | x)P(x) dx}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But notice that $P(s, f | x)$, the likelihood function, actually follows the binomial probability distribution, and the $P(x)$ simply follows the beta distribution:\n",
    "\n",
    "$$P(s, f | q = x) = {s + f \\choose s}x^s (1-x)^{f}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(x) = \\frac{x^{\\alpha - 1} (1-x)^{\\beta - 1}}{B(\\alpha, \\beta)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But notice that these are the only two terms we need to define to substitute into the expression for $P(q = x | s, f)$. In fact, let's do this substitution to see what the posterior distribution looks like!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(q = x | s, f) = \\frac{P(s, f | x) P(x)}{\\int P(s, f | x)P(x) dx}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ = \\frac{{s + f \\choose s}x^s (1-x)^{f} x^{\\alpha - 1} (1-x)^{\\beta - 1} / B(\\alpha, \\beta)}{\\int P(s, f | x)P(x) dx}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ = \\frac{{s + f \\choose s}x^{s + \\alpha - 1} (1-x)^{f + \\beta - 1} / B(\\alpha, \\beta)}{\\int {s + f \\choose s}x^{s + \\alpha - 1} (1-x)^{f + \\beta - 1} / B(\\alpha, \\beta) dx}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ = \\frac{x^{s + \\alpha - 1} (1-x)^{f + \\beta - 1} / B(\\alpha, \\beta)}{\\int x^{s + \\alpha - 1} (1-x)^{f + \\beta - 1} / B(\\alpha, \\beta) dx}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ = \\frac{x^{s + \\alpha - 1} (1-x)^{f + \\beta - 1}}{B(s + \\alpha, f + \\beta)}$$\n",
    "\n",
    "which is actually **another Beta distribution** with parameters $(\\alpha + s, \\beta + f)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we see that using the beta distribution for the prior with a binomial likelihood function is really nice mathematically because the beta distribution is a **conjugate prior** and thus the posterior is also a beta distribution with the very nice and easy update rule of $\\alpha_{posterior} = \\alpha + s$ and $\\beta_{posterior} = \\beta + f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
